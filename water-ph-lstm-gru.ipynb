{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9cb45-832e-4ba0-a956-8988352835b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "  THESIS: Hybrid LSTM-GRU untuk Prediksi pH Akuaponik\n",
      "  TensorFlow version : 2.20.0\n",
      "=================================================================\n",
      "\n",
      "=================================================================\n",
      "  MEMULAI PIPELINE PENELITIAN\n",
      "  Waktu mulai: 2026-02-10 18:05:01\n",
      "=================================================================\n",
      "\n",
      "=================================================================\n",
      "  TAHAP PREPROCESSING DATA  (BAB IV.3)\n",
      "=================================================================\n",
      "\n",
      "[1/8] MEMUAT DATASET ...\n",
      "      Ukuran dataset awal  : 118,286 baris x 5 kolom\n",
      "      Kolom               : ['id', 'created_date', 'water_pH', 'TDS', 'water_temp']\n",
      "      Kolom timestamp      : 'created_date'\n",
      "      Rentang data         : 2023-01-26 11:24:00 s/d 2023-03-22 17:53:00\n",
      "\n",
      "      Statistik Deskriptif:\n",
      "               count        mean        std    min     25%     50%     75%     max  skewness  kurtosis\n",
      "water_pH    118286.0    7.508481   0.555780    6.5    7.05    7.49    7.98    8.50  0.066338 -1.086233\n",
      "TDS         118286.0  335.416491  43.738700  241.0  305.00  325.00  353.00  498.00  0.952200  0.467764\n",
      "water_temp  118286.0   24.656045   0.452398   24.0   24.31   24.56   24.94   26.19  0.811410  0.243488\n",
      "      Tidak ada missing values ditemukan.\n",
      "      Outlier ditemukan    : 6 titik â†’ diisi interpolasi\n",
      "\n",
      "      Missing values sebelum: {'water_pH': 0, 'TDS': 6, 'water_temp': 0}\n",
      "      Missing values setelah: {'water_pH': 0, 'TDS': 0, 'water_temp': 0}\n",
      "      Moving Average smoothing diterapkan (window=3)\n",
      "      Min-Max Normalization diterapkan untuk semua fitur.\n",
      "\n",
      "      Dataset final        : 118,286 baris\n",
      "\n",
      "[2/8] ANALISIS KORELASI PEARSON ...\n",
      "      Matriks Korelasi Pearson:\n",
      "            water_pH       TDS  water_temp\n",
      "water_pH    1.000000  0.046421   -0.039061\n",
      "TDS         0.046421  1.000000   -0.182604\n",
      "water_temp -0.039061 -0.182604    1.000000\n",
      "\n",
      "[2/8] MEMBUAT VISUALISASI EDA ...\n",
      "      Gambar tersimpan  : plots/01_time_series_overview.png\n",
      "      Gambar tersimpan  : plots/02_pearson_correlation.png\n",
      "      Gambar tersimpan  : plots/03_distribution.png\n",
      "\n",
      "[3/8] PEMBAGIAN DATASET ...\n",
      "      X_train : (85156, 12, 3)   y_train : (85156,)\n",
      "      X_val   : (9461, 12, 3)   y_val   : (9461,)\n",
      "      X_test  : (23657, 12, 3)   y_test  : (23657,)\n",
      "\n",
      "[4/8] HYPERPARAMETER TUNING (Hybrid LSTM-GRU) ...\n",
      "      Skenario yang diuji:\n",
      "        Epochs      : [10]\n",
      "        LR          : [0.001]\n",
      "        Hidden Units: [(64, 32)]\n",
      "      Total percobaan     : 1\n",
      "\n",
      "      Training HybridLSTMGRU | epochs=10 | batch=64 ... Selesai 127.6s | best epoch=3 | val_loss=0.028397\n",
      "WARNING:tensorflow:From c:\\Users\\amant\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "      Tabel Hasil Tuning (Top 5):\n",
      " trial  epochs    lr  units_1  units_2  val_loss  actual_ep\n",
      "     1      10 0.001       64       32  0.028397         10\n",
      "\n",
      "      âœ“ Konfigurasi Terbaik:\n",
      "        Epochs   : 10\n",
      "        LR       : 0.001\n",
      "        Units    : (64, 32)\n",
      "        Val Loss : 0.028397\n",
      "      Gambar tersimpan  : plots/09_tuning_heatmap.png\n",
      "\n",
      "[5/8] TRAINING MODEL FINAL ...\n",
      "      Training LSTM | epochs=10 | batch=64 ... Selesai 16300.5s | best epoch=9 | val_loss=0.020101\n",
      "      Training GRU | epochs=10 | batch=64 ... Selesai 330.5s | best epoch=9 | val_loss=0.018805\n",
      "      Training HybridLSTMGRU | epochs=10 | batch=64 ... Selesai 228.3s | best epoch=10 | val_loss=0.023355\n",
      "      Model final tersimpan di outputs/models/\n",
      "\n",
      "      Ringkasan Arsitektur:\n",
      "\n",
      "      -- LSTM --\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model: \"LSTM_Model\"\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
      "â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ\n",
      "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
      "â”‚ input (InputLayer)              â”‚ (None, 12, 3)          â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ lstm_1 (LSTM)                   â”‚ (None, 12, 64)         â”‚        17,408 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_1 (Dropout)             â”‚ (None, 12, 64)         â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ lstm_2 (LSTM)                   â”‚ (None, 32)             â”‚        12,416 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_2 (Dropout)             â”‚ (None, 32)             â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dense_hidden (Dense)            â”‚ (None, 16)             â”‚           528 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ output (Dense)                  â”‚ (None, 1)              â”‚            17 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      " Total params: 91,109 (355.90 KB)\n",
      " Trainable params: 30,369 (118.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 60,740 (237.27 KB)\n",
      "\n",
      "\n",
      "      -- GRU --\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model: \"GRU_Model\"\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
      "â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ\n",
      "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
      "â”‚ input (InputLayer)              â”‚ (None, 12, 3)          â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ gru_1 (GRU)                     â”‚ (None, 12, 64)         â”‚        13,248 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_1 (Dropout)             â”‚ (None, 12, 64)         â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ gru_2 (GRU)                     â”‚ (None, 32)             â”‚         9,408 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_2 (Dropout)             â”‚ (None, 32)             â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dense_hidden (Dense)            â”‚ (None, 16)             â”‚           528 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ output (Dense)                  â”‚ (None, 1)              â”‚            17 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      " Total params: 69,605 (271.90 KB)\n",
      " Trainable params: 23,201 (90.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 46,404 (181.27 KB)\n",
      "\n",
      "\n",
      "      -- Hybrid LSTM-GRU --\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model: \"Hybrid_LSTM_GRU_Model\"\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
      "â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ\n",
      "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
      "â”‚ input (InputLayer)              â”‚ (None, 12, 3)          â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ lstm_1 (LSTM)                   â”‚ (None, 12, 64)         â”‚        17,408 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_1 (Dropout)             â”‚ (None, 12, 64)         â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ gru_2 (GRU)                     â”‚ (None, 32)             â”‚         9,408 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dropout_2 (Dropout)             â”‚ (None, 32)             â”‚             0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dense_hidden (Dense)            â”‚ (None, 16)             â”‚           528 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ output (Dense)                  â”‚ (None, 1)              â”‚            17 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      " Total params: 82,085 (320.65 KB)\n",
      " Trainable params: 27,361 (106.88 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 54,724 (213.77 KB)\n",
      "\n",
      "      Gambar tersimpan  : plots/04_training_history.png\n",
      "\n",
      "[6/8] EVALUASI KOMPARATIF MODEL ...\n",
      "      Model                          |       RMSE |        MAE |       RÂ²\n",
      "      --------------------------------------------------------------------\n",
      "      LSTM                           | RMSE=0.278485 | MAE=0.231319 | RÂ²=0.677452\n",
      "      GRU                            | RMSE=0.279669 | MAE=0.234793 | RÂ²=0.674704\n",
      "      Hybrid LSTM-GRU                | RMSE=0.294736 | MAE=0.247309 | RÂ²=0.638708\n",
      "\n",
      "      Tabel tersimpan: c:\\Users\\amant\\Documents\\GitHub\\waterquality-forecasting\\outputs/evaluation_metrics.csv\n",
      "\n",
      "[7/8] MEMBUAT VISUALISASI HASIL ...\n",
      "      Gambar tersimpan  : plots/05_prediction_comparison.png\n",
      "      Gambar tersimpan  : plots/06_scatter_actual_vs_pred.png\n",
      "      Gambar tersimpan  : plots/07_metrics_comparison.png\n",
      "      Gambar tersimpan  : plots/08_error_distribution.png\n",
      "\n",
      "=================================================================\n",
      "  RINGKASAN HASIL AKHIR\n",
      "=================================================================\n",
      "                      MSE      RMSE       MAE        R2\n",
      "Model                                                  \n",
      "LSTM             0.077554  0.278485  0.231319  0.677452\n",
      "GRU              0.078215  0.279669  0.234793  0.674704\n",
      "Hybrid LSTM-GRU  0.086870  0.294736  0.247309  0.638708\n",
      "\n",
      "  âœ“ Model Terbaik (RMSE terendah) : LSTM\n",
      "    RMSE : 0.278485\n",
      "    MAE  : 0.231319\n",
      "    RÂ²   : 0.677452\n",
      "\n",
      "  Total waktu eksekusi : 283.5 menit\n",
      "  Output tersimpan di  : C:\\Users\\amant\\Documents\\GitHub\\waterquality-forecasting\\outputs\n",
      "\n",
      "  File Output:\n",
      "    ğŸ“Š outputs/plots/          â†’ 9 grafik visualisasi\n",
      "    ğŸ¤– outputs/models/         â†’ 3 model (.keras)\n",
      "    ğŸ“‹ outputs/evaluation_metrics.csv\n",
      "    ğŸ“‹ outputs/tuning_results.csv\n",
      "    ğŸ“ outputs/logs/           â†’ training logs CSV\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TESIS: Prediksi pH Sistem Akuaponik Menggunakan Model Hybrid LSTM-GRU\n",
    "# Author  : Ardi\n",
    "# Program : Magister Data Science - Institut Teknologi dan Bisnis STIKOM Bali\n",
    "# Python  : 3.12 | TensorFlow/Keras | Spyder 6.1.2\n",
    "# =============================================================================\n",
    "# STRUKTUR FILE:\n",
    "#   1. Import & Konfigurasi Global\n",
    "#   2. Fungsi Preprocessing Data\n",
    "#   3. Fungsi Feature Engineering\n",
    "#   4. Fungsi Pembangunan Model (LSTM, GRU, Hybrid LSTM-GRU)\n",
    "#   5. Fungsi Training & Hyperparameter Tuning\n",
    "#   6. Fungsi Evaluasi & Metrik\n",
    "#   7. Fungsi Visualisasi\n",
    "#   8. Main Pipeline (Eksekusi Utama)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 1: IMPORT & KONFIGURASI GLOBAL\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')   # Untuk Spyder: ganti ke 'Qt5Agg' jika ingin inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# TensorFlow / Keras\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   # Suppress TF info logs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, GRU, Dense, Dropout,\n",
    "    LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint,\n",
    "    ReduceLROnPlateau, CSVLogger\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# SEED â€“ Reproducibility\n",
    "# -------------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# PATH KONFIGURASI\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR    = Path(__file__).parent          # folder yang sama dengan script\n",
    "DATA_PATH   = BASE_DIR / \"sources\" / \"aquaponic_letuce_dataset_.csv\"\n",
    "OUTPUT_DIR  = BASE_DIR / \"outputs\"\n",
    "MODEL_DIR   = OUTPUT_DIR / \"models\"\n",
    "PLOT_DIR    = OUTPUT_DIR / \"plots\"\n",
    "LOG_DIR     = OUTPUT_DIR / \"logs\"\n",
    "\n",
    "for d in [OUTPUT_DIR, MODEL_DIR, PLOT_DIR, LOG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# HYPERPARAMETER GLOBAL (sesuai proposal BAB IV)\n",
    "# -------------------------------------------------------------------\n",
    "CFG = {\n",
    "    # Data\n",
    "    \"target_col\"    : \"water_pH\",\n",
    "    \"feature_cols\"  : [\"water_pH\", \"TDS\", \"water_temp\"],\n",
    "    \"test_size\"     : 0.20,          # 80-20 split\n",
    "    \"val_size\"      : 0.10,          # 10% dari train untuk validasi\n",
    "\n",
    "    # Sliding window\n",
    "    \"timesteps\"     : 12,            # panjang jendela waktu (lag)\n",
    "    \"n_features\"    : 3,             # pH, TDS, suhu\n",
    "\n",
    "    # Arsitektur model\n",
    "    \"lstm_units_1\"  : 64,\n",
    "    \"lstm_units_2\"  : 32,\n",
    "    \"gru_units_1\"   : 64,\n",
    "    \"gru_units_2\"   : 32,\n",
    "    \"dense_units\"   : 16,\n",
    "    \"dropout_rate\"  : 0.2,\n",
    "\n",
    "    # Training\n",
    "    \"batch_size\"    : 64,\n",
    "    \"patience\"      : 15,            # EarlyStopping\n",
    "    \"reduce_lr_pat\" : 7,\n",
    "\n",
    "    # Hyperparameter Tuning Skenario (BAB IV.4)\n",
    "    # -- SET 1 PERCOBAAN DULU UNTUK TESTING --\n",
    "    \"epoch_variants\"  : [10],\n",
    "    \"lr_variants\"     : [0.001],\n",
    "    \"unit_variants\"   : [(64, 32)],\n",
    "\n",
    "    # Smoothing\n",
    "    \"ma_window\"     : 3,\n",
    "\n",
    "    # Grafik\n",
    "    \"fig_dpi\"       : 150,\n",
    "}\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  THESIS: Hybrid LSTM-GRU untuk Prediksi pH Akuaponik\")\n",
    "print(\"  TensorFlow version :\", tf.__version__)\n",
    "print(\"=\" * 65)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 2: FUNGSI PREPROCESSING DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_inspect(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Memuat CSV, auto-detect kolom timestamp, dan cetak ringkasan awal.\n",
    "    Sesuai BAB IV.3.1 - Persiapan Data.\n",
    "    \"\"\"\n",
    "    print(\"\\n[1/8] MEMUAT DATASET ...\")\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"File tidak ditemukan: {path}\\n\"\n",
    "            f\"Pastikan CSV ada di: {path.parent}\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"      Ukuran dataset awal  : {df.shape[0]:,} baris x {df.shape[1]} kolom\")\n",
    "    print(f\"      Kolom               : {list(df.columns)}\")\n",
    "\n",
    "    # --- Auto-detect & parse kolom timestamp ---\n",
    "    ts_candidates = [c for c in df.columns\n",
    "                     if any(k in c.lower() for k in [\"time\", \"date\", \"stamp\", \"ts\"])]\n",
    "    if ts_candidates:\n",
    "        ts_col = ts_candidates[0]\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.set_index(ts_col).sort_index()\n",
    "        print(f\"      Kolom timestamp      : '{ts_col}'\")\n",
    "        print(f\"      Rentang data         : {df.index.min()} s/d {df.index.max()}\")\n",
    "    else:\n",
    "        print(\"      [PERINGATAN] Kolom timestamp tidak ditemukan. Menggunakan indeks integer.\")\n",
    "\n",
    "    # --- Auto-rename kolom ke nama standar jika berbeda ---\n",
    "    rename_map = {}\n",
    "    for col in df.columns:\n",
    "        cl = col.lower().replace(\" \", \"_\")\n",
    "        if \"ph\"   in cl and col != \"water_pH\":  rename_map[col] = \"water_pH\"\n",
    "        if \"tds\"  in cl and col != \"TDS\":        rename_map[col] = \"TDS\"\n",
    "        if \"temp\" in cl and col != \"water_temp\": rename_map[col] = \"water_temp\"\n",
    "    if rename_map:\n",
    "        df.rename(columns=rename_map, inplace=True)\n",
    "        print(f\"      Kolom di-rename      : {rename_map}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def descriptive_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Statistik deskriptif untuk EDA.\"\"\"\n",
    "    stats = df[CFG[\"feature_cols\"]].describe().T\n",
    "    stats[\"skewness\"] = df[CFG[\"feature_cols\"]].skew()\n",
    "    stats[\"kurtosis\"] = df[CFG[\"feature_cols\"]].kurt()\n",
    "    print(\"\\n      Statistik Deskriptif:\")\n",
    "    print(stats.to_string())\n",
    "    return stats\n",
    "\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Penanganan nilai hilang:\n",
    "    - Interpolasi linier (BAB IV.3.2.1)\n",
    "    - Forward fill untuk sisa NaN\n",
    "    Sesuai persamaan interpolasi linier di BAB III.4.1.\n",
    "    \"\"\"\n",
    "    missing_before = df[CFG[\"feature_cols\"]].isnull().sum()\n",
    "    if missing_before.sum() > 0:\n",
    "        print(f\"\\n      Missing values sebelum: {missing_before.to_dict()}\")\n",
    "        df[CFG[\"feature_cols\"]] = (\n",
    "            df[CFG[\"feature_cols\"]]\n",
    "            .interpolate(method='linear', limit_direction='both')\n",
    "            .ffill()\n",
    "            .bfill()\n",
    "        )\n",
    "        missing_after = df[CFG[\"feature_cols\"]].isnull().sum()\n",
    "        print(f\"      Missing values setelah: {missing_after.to_dict()}\")\n",
    "    else:\n",
    "        print(\"      Tidak ada missing values ditemukan.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Deteksi dan penanganan outlier menggunakan metode IQR.\n",
    "    Sesuai BAB IV.3.2 - Outlier Detection.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    total_removed = 0\n",
    "    for col in CFG[\"feature_cols\"]:\n",
    "        Q1  = df_clean[col].quantile(0.25)\n",
    "        Q3  = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 3.0 * IQR    # batas longgar agar data sensor tidak terlalu banyak dibuang\n",
    "        upper = Q3 + 3.0 * IQR\n",
    "        mask  = (df_clean[col] < lower) | (df_clean[col] > upper)\n",
    "        n_out = mask.sum()\n",
    "        if n_out > 0:\n",
    "            df_clean.loc[mask, col] = np.nan   # ganti dulu jadi NaN\n",
    "            total_removed += n_out\n",
    "    if total_removed:\n",
    "        print(f\"      Outlier ditemukan    : {total_removed:,} titik â†’ diisi interpolasi\")\n",
    "        df_clean = handle_missing_values(df_clean)\n",
    "    else:\n",
    "        print(\"      Tidak ada outlier signifikan.\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Hapus duplikat (BAB IV.3.1 - Duplicate Removal).\"\"\"\n",
    "    n_dup = df.duplicated().sum()\n",
    "    if n_dup:\n",
    "        df = df[~df.duplicated()]\n",
    "        print(f\"      Duplikat dihapus     : {n_dup:,} baris\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_moving_average(df: pd.DataFrame, window: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Smoothing dengan moving average untuk meredam noise sensor.\n",
    "    Sesuai BAB IV.3.2.2 & persamaan MA(t).\n",
    "    \"\"\"\n",
    "    for col in CFG[\"feature_cols\"]:\n",
    "        df[col] = (df[col]\n",
    "                   .rolling(window=window, min_periods=1, center=True)\n",
    "                   .mean())\n",
    "    print(f\"      Moving Average smoothing diterapkan (window={window})\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_features(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Min-Max Normalization ke [0, 1].\n",
    "    Sesuai BAB III.4.2 & BAB IV.3.2.3.\n",
    "    Mengembalikan (df_scaled, scaler_dict).\n",
    "    \"\"\"\n",
    "    scalers = {}\n",
    "    df_scaled = df.copy()\n",
    "    for col in CFG[\"feature_cols\"]:\n",
    "        sc = MinMaxScaler(feature_range=(0, 1))\n",
    "        df_scaled[col] = sc.fit_transform(df_scaled[[col]])\n",
    "        scalers[col] = sc\n",
    "    print(\"      Min-Max Normalization diterapkan untuk semua fitur.\")\n",
    "    return df_scaled, scalers\n",
    "\n",
    "\n",
    "def full_preprocessing(path: Path):\n",
    "    \"\"\"\n",
    "    Pipeline preprocessing lengkap â€” memanggil semua langkah berurutan.\n",
    "    Mengembalikan (df_raw, df_processed, scalers).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 65)\n",
    "    print(\"  TAHAP PREPROCESSING DATA  (BAB IV.3)\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    df_raw      = load_and_inspect(path)\n",
    "    stats       = descriptive_stats(df_raw)\n",
    "    df          = remove_duplicates(df_raw.copy())\n",
    "    df          = handle_missing_values(df)\n",
    "    df          = remove_outliers_iqr(df)\n",
    "    df          = apply_moving_average(df, window=CFG[\"ma_window\"])\n",
    "    df_scaled, scalers = normalize_features(df)\n",
    "\n",
    "    print(f\"\\n      Dataset final        : {df_scaled.shape[0]:,} baris\")\n",
    "    return df_raw, df_scaled, scalers, stats\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 3: FEATURE ENGINEERING & PEMBENTUKAN DATASET\n",
    "# =============================================================================\n",
    "\n",
    "def pearson_correlation_analysis(df_raw: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analisis korelasi Pearson antara pH, TDS, dan suhu.\n",
    "    Sesuai BAB III.4.3 & BAB II.5.3 - Optimasi Fitur Multivariat.\n",
    "    \"\"\"\n",
    "    print(\"\\n[2/8] ANALISIS KORELASI PEARSON ...\")\n",
    "    corr_matrix = df_raw[CFG[\"feature_cols\"]].corr(method='pearson')\n",
    "    print(\"      Matriks Korelasi Pearson:\")\n",
    "    print(corr_matrix.to_string())\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "def create_sliding_window(data: np.ndarray, timesteps: int):\n",
    "    \"\"\"\n",
    "    Transformasi time series ke format supervised learning\n",
    "    menggunakan metode jendela geser (sliding window).\n",
    "    Sesuai BAB III.3 - persamaan X_t dan Y_t.\n",
    "\n",
    "    Input  : data shape (N, n_features)\n",
    "    Output : X shape (N-timesteps, timesteps, n_features)\n",
    "             y shape (N-timesteps,)  â† hanya kolom pH (indeks 0)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    ph_idx = CFG[\"feature_cols\"].index(CFG[\"target_col\"])   # indeks kolom pH\n",
    "    for i in range(timesteps, len(data)):\n",
    "        X.append(data[i - timesteps: i, :])       # semua fitur dalam window\n",
    "        y.append(data[i, ph_idx])                 # target = pH berikutnya\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def split_dataset(df_scaled: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Pembagian dataset: Train 80% | Test 20% (sequential, tidak diacak).\n",
    "    Sesuai BAB IV.3.2.4.\n",
    "    Mengembalikan (X_train, X_val, X_test, y_train, y_val, y_test).\n",
    "    \"\"\"\n",
    "    print(\"\\n[3/8] PEMBAGIAN DATASET ...\")\n",
    "    data = df_scaled[CFG[\"feature_cols\"]].values\n",
    "\n",
    "    # Split sekuensial\n",
    "    n         = len(data)\n",
    "    n_test    = int(n * CFG[\"test_size\"])\n",
    "    n_train   = n - n_test\n",
    "\n",
    "    train_raw = data[:n_train]\n",
    "    test_raw  = data[n_train - CFG[\"timesteps\"]:]   # include overlap untuk window\n",
    "\n",
    "    X_train_full, y_train_full = create_sliding_window(train_raw, CFG[\"timesteps\"])\n",
    "    X_test,       y_test       = create_sliding_window(test_raw,  CFG[\"timesteps\"])\n",
    "\n",
    "    # Pisahkan validation dari training\n",
    "    n_val    = int(len(X_train_full) * CFG[\"val_size\"])\n",
    "    X_val    = X_train_full[-n_val:]\n",
    "    y_val    = y_train_full[-n_val:]\n",
    "    X_train  = X_train_full[:-n_val]\n",
    "    y_train  = y_train_full[:-n_val]\n",
    "\n",
    "    print(f\"      X_train : {X_train.shape}   y_train : {y_train.shape}\")\n",
    "    print(f\"      X_val   : {X_val.shape}   y_val   : {y_val.shape}\")\n",
    "    print(f\"      X_test  : {X_test.shape}   y_test  : {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 4: ARSITEKTUR MODEL  (BAB IV.3.3)\n",
    "# =============================================================================\n",
    "\n",
    "def build_lstm_model(units_1=64, units_2=32, dense_units=16,\n",
    "                     dropout=0.2, lr=0.001) -> Model:\n",
    "    \"\"\"\n",
    "    Model LSTM Baseline.\n",
    "    Sesuai Tabel BAB IV.3.3.1\n",
    "    \"\"\"\n",
    "    inp  = Input(shape=(CFG[\"timesteps\"], CFG[\"n_features\"]), name=\"input\")\n",
    "    x    = LSTM(units_1, return_sequences=True,\n",
    "                activation='tanh', name=\"lstm_1\")(inp)\n",
    "    x    = Dropout(dropout, name=\"dropout_1\")(x)\n",
    "    x    = LSTM(units_2, return_sequences=False,\n",
    "                activation='tanh', name=\"lstm_2\")(x)\n",
    "    x    = Dropout(dropout, name=\"dropout_2\")(x)\n",
    "    x    = Dense(dense_units, activation='relu', name=\"dense_hidden\")(x)\n",
    "    out  = Dense(1, activation='linear', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out, name=\"LSTM_Model\")\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gru_model(units_1=64, units_2=32, dense_units=16,\n",
    "                    dropout=0.2, lr=0.001) -> Model:\n",
    "    \"\"\"\n",
    "    Model GRU Baseline.\n",
    "    Sesuai Tabel BAB IV.3.3.2\n",
    "    \"\"\"\n",
    "    inp  = Input(shape=(CFG[\"timesteps\"], CFG[\"n_features\"]), name=\"input\")\n",
    "    x    = GRU(units_1, return_sequences=True,\n",
    "               activation='tanh', name=\"gru_1\")(inp)\n",
    "    x    = Dropout(dropout, name=\"dropout_1\")(x)\n",
    "    x    = GRU(units_2, return_sequences=False,\n",
    "               activation='tanh', name=\"gru_2\")(x)\n",
    "    x    = Dropout(dropout, name=\"dropout_2\")(x)\n",
    "    x    = Dense(dense_units, activation='relu', name=\"dense_hidden\")(x)\n",
    "    out  = Dense(1, activation='linear', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out, name=\"GRU_Model\")\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_hybrid_lstm_gru_model(units_1=64, units_2=32, dense_units=16,\n",
    "                                dropout=0.2, lr=0.001) -> Model:\n",
    "    \"\"\"\n",
    "    Model Hybrid LSTM-GRU (MODEL USULAN).\n",
    "    Layer 1 : LSTM â€“ menangkap dependensi jangka panjang\n",
    "    Layer 2 : GRU  â€“ efisiensi komputasi pola jangka pendek\n",
    "    Sesuai Tabel BAB IV.3.3.3 & BAB III.5.4 (Arsitektur Sekuensial).\n",
    "    \"\"\"\n",
    "    inp  = Input(shape=(CFG[\"timesteps\"], CFG[\"n_features\"]), name=\"input\")\n",
    "    # LSTM Layer: return_sequences=True â†’ meneruskan seluruh sekuens ke GRU\n",
    "    x    = LSTM(units_1, return_sequences=True,\n",
    "                activation='tanh', name=\"lstm_1\")(inp)\n",
    "    x    = Dropout(dropout, name=\"dropout_1\")(x)\n",
    "    # GRU Layer: return_sequences=False â†’ hanya output terakhir\n",
    "    x    = GRU(units_2, return_sequences=False,\n",
    "               activation='tanh', name=\"gru_2\")(x)\n",
    "    x    = Dropout(dropout, name=\"dropout_2\")(x)\n",
    "    x    = Dense(dense_units, activation='relu', name=\"dense_hidden\")(x)\n",
    "    out  = Dense(1, activation='linear', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out, name=\"Hybrid_LSTM_GRU_Model\")\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_callbacks(model_name: str, fold_id: str = \"\") -> list:\n",
    "    \"\"\"Callbacks standar untuk semua model.\"\"\"\n",
    "    suffix = f\"_{fold_id}\" if fold_id else \"\"\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_loss', patience=CFG[\"patience\"],\n",
    "                      restore_best_weights=True, verbose=0),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(MODEL_DIR / f\"{model_name}{suffix}_best.keras\"),\n",
    "            monitor='val_loss', save_best_only=True, verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                          patience=CFG[\"reduce_lr_pat\"], min_lr=1e-6, verbose=0),\n",
    "        CSVLogger(str(LOG_DIR / f\"{model_name}{suffix}_log.csv\"), append=False),\n",
    "    ]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 5: TRAINING & HYPERPARAMETER TUNING  (BAB IV.3.4)\n",
    "# =============================================================================\n",
    "\n",
    "def train_model(model, model_name, X_train, y_train, X_val, y_val,\n",
    "                epochs=100, batch_size=64, fold_id=\"\"):\n",
    "    \"\"\"\n",
    "    Melatih satu model dan mengembalikan (model, history).\n",
    "    \"\"\"\n",
    "    print(f\"      Training {model_name} | epochs={epochs} | \"\n",
    "          f\"batch={batch_size} ...\", end=\" \", flush=True)\n",
    "    t0 = datetime.now()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=get_callbacks(model_name, fold_id),\n",
    "        verbose=0,\n",
    "        shuffle=False,     # time series â€” jangan diacak\n",
    "    )\n",
    "    elapsed = (datetime.now() - t0).total_seconds()\n",
    "    best_ep = np.argmin(history.history['val_loss']) + 1\n",
    "    best_vl = min(history.history['val_loss'])\n",
    "    print(f\"Selesai {elapsed:.1f}s | best epoch={best_ep} | \"\n",
    "          f\"val_loss={best_vl:.6f}\")\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning sesuai BAB IV.3.4 - Model LSTM-GRU:\n",
    "      - Variasi epoch      : [50, 75, 100, 150]\n",
    "      - Variasi LR         : [0.0005, 0.001, 0.002]\n",
    "      - Variasi hidden units: [(32,16), (64,32), (128,64)]\n",
    "    Mengembalikan konfigurasi terbaik berdasarkan val_loss terendah.\n",
    "    \"\"\"\n",
    "    print(\"\\n[4/8] HYPERPARAMETER TUNING (Hybrid LSTM-GRU) ...\")\n",
    "    print(\"      Skenario yang diuji:\")\n",
    "    print(f\"        Epochs      : {CFG['epoch_variants']}\")\n",
    "    print(f\"        LR          : {CFG['lr_variants']}\")\n",
    "    print(f\"        Hidden Units: {CFG['unit_variants']}\")\n",
    "\n",
    "    results = []\n",
    "    trial   = 0\n",
    "\n",
    "    total_trials = (len(CFG[\"epoch_variants\"]) *\n",
    "                    len(CFG[\"lr_variants\"]) *\n",
    "                    len(CFG[\"unit_variants\"]))\n",
    "    print(f\"      Total percobaan     : {total_trials}\\n\")\n",
    "\n",
    "    for ep in CFG[\"epoch_variants\"]:\n",
    "        for lr in CFG[\"lr_variants\"]:\n",
    "            for (u1, u2) in CFG[\"unit_variants\"]:\n",
    "                trial += 1\n",
    "                m = build_hybrid_lstm_gru_model(\n",
    "                    units_1=u1, units_2=u2,\n",
    "                    dense_units=CFG[\"dense_units\"],\n",
    "                    dropout=CFG[\"dropout_rate\"],\n",
    "                    lr=lr\n",
    "                )\n",
    "                fold_id = f\"tune_ep{ep}_lr{str(lr).replace('.','')}_u{u1}x{u2}\"\n",
    "                m, hist = train_model(\n",
    "                    m, \"HybridLSTMGRU\", X_train, y_train, X_val, y_val,\n",
    "                    epochs=ep, batch_size=CFG[\"batch_size\"], fold_id=fold_id\n",
    "                )\n",
    "                best_val_loss = min(hist.history['val_loss'])\n",
    "                actual_epochs = len(hist.history['val_loss'])\n",
    "                results.append({\n",
    "                    \"trial\"       : trial,\n",
    "                    \"epochs\"      : ep,\n",
    "                    \"lr\"          : lr,\n",
    "                    \"units_1\"     : u1,\n",
    "                    \"units_2\"     : u2,\n",
    "                    \"val_loss\"    : best_val_loss,\n",
    "                    \"actual_ep\"   : actual_epochs,\n",
    "                    \"model\"       : m,\n",
    "                    \"history\"     : hist,\n",
    "                })\n",
    "                tf.keras.backend.clear_session()    # bebaskan memori GPU/CPU\n",
    "\n",
    "    # Pilih berdasarkan val_loss minimum\n",
    "    df_res = pd.DataFrame([\n",
    "        {k: v for k, v in r.items() if k not in [\"model\", \"history\"]}\n",
    "        for r in results\n",
    "    ])\n",
    "    df_res.to_csv(OUTPUT_DIR / \"tuning_results.csv\", index=False)\n",
    "    print(\"\\n      Tabel Hasil Tuning (Top 5):\")\n",
    "    print(df_res.nsmallest(5, \"val_loss\").to_string(index=False))\n",
    "\n",
    "    best_idx  = df_res[\"val_loss\"].idxmin()\n",
    "    best_cfg  = results[best_idx]\n",
    "    print(f\"\\n      âœ“ Konfigurasi Terbaik:\")\n",
    "    print(f\"        Epochs   : {best_cfg['epochs']}\")\n",
    "    print(f\"        LR       : {best_cfg['lr']}\")\n",
    "    print(f\"        Units    : ({best_cfg['units_1']}, {best_cfg['units_2']})\")\n",
    "    print(f\"        Val Loss : {best_cfg['val_loss']:.6f}\")\n",
    "\n",
    "    return best_cfg, df_res\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 6: EVALUASI & METRIK  (BAB III.6 & BAB IV.3.5)\n",
    "# =============================================================================\n",
    "\n",
    "def inverse_transform_predictions(y_pred_scaled, y_true_scaled, scalers):\n",
    "    \"\"\"\n",
    "    Mengubah prediksi yang ternormalisasi kembali ke skala pH asli.\n",
    "    \"\"\"\n",
    "    sc = scalers[CFG[\"target_col\"]]\n",
    "    y_pred = sc.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "    y_true = sc.inverse_transform(y_true_scaled.reshape(-1, 1)).flatten()\n",
    "    return y_pred, y_true\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                    model_name: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Menghitung RMSE, MAE, RÂ² sesuai BAB III.6 & BAB IV.3.5.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mse  = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    metrics = {\"Model\": model_name, \"MSE\": mse, \"RMSE\": rmse,\n",
    "               \"MAE\": mae, \"R2\": r2}\n",
    "    print(f\"      {model_name:30s} | RMSE={rmse:.6f} | \"\n",
    "          f\"MAE={mae:.6f} | RÂ²={r2:.6f}\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate_all_models(models_dict: dict, X_test, y_test, scalers) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluasi semua model secara serentak dan kembalikan tabel perbandingan.\n",
    "    \"\"\"\n",
    "    print(\"\\n[6/8] EVALUASI KOMPARATIF MODEL ...\")\n",
    "    print(f\"      {'Model':30s} | {'RMSE':>10} | {'MAE':>10} | {'RÂ²':>8}\")\n",
    "    print(\"      \" + \"-\" * 68)\n",
    "\n",
    "    all_metrics  = []\n",
    "    all_preds    = {}\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        y_pred_sc = model.predict(X_test, verbose=0).flatten()\n",
    "        y_pred, y_true = inverse_transform_predictions(y_pred_sc, y_test, scalers)\n",
    "        m = compute_metrics(y_true, y_pred, name)\n",
    "        all_metrics.append(m)\n",
    "        all_preds[name] = {\"y_pred\": y_pred, \"y_true\": y_true}\n",
    "\n",
    "    df_metrics = pd.DataFrame(all_metrics).set_index(\"Model\")\n",
    "    df_metrics.to_csv(OUTPUT_DIR / \"evaluation_metrics.csv\")\n",
    "    print(f\"\\n      Tabel tersimpan: {OUTPUT_DIR}/evaluation_metrics.csv\")\n",
    "    return df_metrics, all_preds\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 7: VISUALISASI\n",
    "# =============================================================================\n",
    "\n",
    "def plot_time_series_overview(df_raw: pd.DataFrame, stats: pd.DataFrame):\n",
    "    \"\"\"Gambar 1: Overview time series mentah (EDA).\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 9), sharex=True)\n",
    "    colors = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "    labels = ['pH Air', 'TDS (ppm)', 'Suhu Air (Â°C)']\n",
    "\n",
    "    for i, (col, color, label) in enumerate(\n",
    "            zip(CFG[\"feature_cols\"], colors, labels)):\n",
    "        if col in df_raw.columns:\n",
    "            axes[i].plot(df_raw.index, df_raw[col],\n",
    "                         color=color, linewidth=0.5, alpha=0.8)\n",
    "            axes[i].set_ylabel(label, fontsize=10)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].set_title(\n",
    "                f\"{label} | Mean={df_raw[col].mean():.3f} | \"\n",
    "                f\"Std={df_raw[col].std():.3f}\", fontsize=9)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Waktu\", fontsize=10)\n",
    "    fig.suptitle(\n",
    "        \"Overview Time Series Parameter Kualitas Air Akuaponik\\n\"\n",
    "        \"(Januari â€“ Maret 2023)\", fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"01_time_series_overview\")\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(corr_matrix: pd.DataFrame):\n",
    "    \"\"\"Gambar 2: Heatmap korelasi Pearson.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".4f\", cmap='coolwarm',\n",
    "                center=0, square=True, linewidths=0.5,\n",
    "                annot_kws={\"size\": 12}, ax=ax)\n",
    "    ax.set_title(\"Matriks Korelasi Pearson\\n(pH, TDS, Suhu)\",\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"02_pearson_correlation\")\n",
    "\n",
    "\n",
    "def plot_distribution(df_raw: pd.DataFrame):\n",
    "    \"\"\"Gambar 3: Distribusi masing-masing fitur.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    colors = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "    labels = ['pH Air', 'TDS (ppm)', 'Suhu Air (Â°C)']\n",
    "\n",
    "    for ax, col, color, label in zip(\n",
    "            axes, CFG[\"feature_cols\"], colors, labels):\n",
    "        if col in df_raw.columns:\n",
    "            ax.hist(df_raw[col].dropna(), bins=50,\n",
    "                    color=color, edgecolor='white', alpha=0.8)\n",
    "            ax.axvline(df_raw[col].mean(), color='red',\n",
    "                       linestyle='--', linewidth=1.5, label='Mean')\n",
    "            ax.set_title(label, fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel(\"Nilai\", fontsize=9)\n",
    "            ax.set_ylabel(\"Frekuensi\", fontsize=9)\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\"Distribusi Parameter Kualitas Air\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"03_distribution\")\n",
    "\n",
    "\n",
    "def plot_training_history(histories: dict):\n",
    "    \"\"\"Gambar 4: Kurva Training & Validation Loss ketiga model.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    colors = {'train': '#2196F3', 'val': '#F44336'}\n",
    "\n",
    "    for ax, (name, hist) in zip(axes, histories.items()):\n",
    "        tl = hist.history['loss']\n",
    "        vl = hist.history['val_loss']\n",
    "        ep = range(1, len(tl) + 1)\n",
    "        ax.plot(ep, tl, color=colors['train'], linewidth=1.5, label='Training Loss')\n",
    "        ax.plot(ep, vl, color=colors['val'],   linewidth=1.5,\n",
    "                linestyle='--', label='Validation Loss')\n",
    "        ax.set_title(name, fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel(\"Epoch\", fontsize=9)\n",
    "        ax.set_ylabel(\"Loss (MSE)\", fontsize=9)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    fig.suptitle(\"Kurva Training vs Validation Loss\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"04_training_history\")\n",
    "\n",
    "\n",
    "def plot_prediction_comparison(all_preds: dict, n_samples: int = 500):\n",
    "    \"\"\"Gambar 5: Perbandingan prediksi vs aktual untuk tiga model.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "    colors = ['#2196F3', '#4CAF50', '#9C27B0']\n",
    "\n",
    "    for ax, (name, preds), color in zip(axes, all_preds.items(), colors):\n",
    "        y_true = preds[\"y_true\"][:n_samples]\n",
    "        y_pred = preds[\"y_pred\"][:n_samples]\n",
    "        x      = range(len(y_true))\n",
    "        ax.plot(x, y_true,  color='gray',  linewidth=1.0,\n",
    "                alpha=0.7, label='Aktual pH')\n",
    "        ax.plot(x, y_pred, color=color, linewidth=1.2,\n",
    "                alpha=0.9, label=f'Prediksi {name}')\n",
    "        ax.fill_between(x, y_true, y_pred,\n",
    "                        alpha=0.15, color=color)\n",
    "        ax.set_ylabel(\"pH\", fontsize=9)\n",
    "        ax.set_title(name, fontsize=10, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='upper right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Indeks Data Test\", fontsize=10)\n",
    "    fig.suptitle(\"Perbandingan Prediksi vs Aktual pH\\n\"\n",
    "                 f\"(n={n_samples} sampel pertama dari test set)\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"05_prediction_comparison\")\n",
    "\n",
    "\n",
    "def plot_scatter_actual_vs_pred(all_preds: dict):\n",
    "    \"\"\"Gambar 6: Scatter plot aktual vs prediksi (ideal = diagonal).\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    colors = ['#2196F3', '#4CAF50', '#9C27B0']\n",
    "\n",
    "    for ax, (name, preds), color in zip(axes, all_preds.items(), colors):\n",
    "        y_true = preds[\"y_true\"]\n",
    "        y_pred = preds[\"y_pred\"]\n",
    "        ax.scatter(y_true, y_pred, alpha=0.15, s=5,\n",
    "                   color=color, rasterized=True)\n",
    "\n",
    "        # Garis ideal y = x\n",
    "        lim = [min(y_true.min(), y_pred.min()) - 0.1,\n",
    "               max(y_true.max(), y_pred.max()) + 0.1]\n",
    "        ax.plot(lim, lim, 'r--', linewidth=1.5, label='Ideal (y = Å·)')\n",
    "        ax.set_xlim(lim); ax.set_ylim(lim)\n",
    "        ax.set_xlabel(\"pH Aktual\", fontsize=9)\n",
    "        ax.set_ylabel(\"pH Prediksi\", fontsize=9)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        ax.set_title(f\"{name}\\nRÂ² = {r2:.4f}\", fontsize=10, fontweight='bold')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\"Scatter Plot: Aktual vs Prediksi pH\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"06_scatter_actual_vs_pred\")\n",
    "\n",
    "\n",
    "def plot_metrics_comparison(df_metrics: pd.DataFrame):\n",
    "    \"\"\"Gambar 7: Bar chart perbandingan metrik ketiga model.\"\"\"\n",
    "    metrics_to_plot = ['RMSE', 'MAE', 'R2']\n",
    "    colors_bar = ['#F44336', '#FF9800', '#4CAF50']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "    for ax, metric, color in zip(axes, metrics_to_plot, colors_bar):\n",
    "        vals   = df_metrics[metric]\n",
    "        models = vals.index.tolist()\n",
    "        bars   = ax.bar(models, vals, color=color, edgecolor='white',\n",
    "                        alpha=0.85, zorder=3)\n",
    "        ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(metric, fontsize=9)\n",
    "        ax.grid(axis='y', alpha=0.4, zorder=0)\n",
    "        ax.tick_params(axis='x', rotation=10, labelsize=8)\n",
    "\n",
    "        # Annotasi nilai di atas bar\n",
    "        for bar, val in zip(bars, vals):\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2.,\n",
    "                    bar.get_height() + max(vals) * 0.02,\n",
    "                    f'{val:.4f}', ha='center', va='bottom',\n",
    "                    fontsize=8, fontweight='bold')\n",
    "\n",
    "        # Tandai model terbaik\n",
    "        best_idx = (vals.idxmin() if metric != 'R2'\n",
    "                    else vals.idxmax())\n",
    "        best_pos = models.index(best_idx)\n",
    "        axes[axes.tolist().index(ax)].patches[best_pos].set_edgecolor('black')\n",
    "        axes[axes.tolist().index(ax)].patches[best_pos].set_linewidth(2.5)\n",
    "\n",
    "    fig.suptitle(\"Perbandingan Metrik Evaluasi Model\\n\"\n",
    "                 \"(garis tebal = model terbaik)\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"07_metrics_comparison\")\n",
    "\n",
    "\n",
    "def plot_error_distribution(all_preds: dict):\n",
    "    \"\"\"Gambar 8: Distribusi error residual.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    colors = ['#2196F3', '#4CAF50', '#9C27B0']\n",
    "\n",
    "    for ax, (name, preds), color in zip(axes, all_preds.items(), colors):\n",
    "        residuals = preds[\"y_true\"] - preds[\"y_pred\"]\n",
    "        ax.hist(residuals, bins=60, color=color, edgecolor='white', alpha=0.8)\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=1.5, label='Zero Error')\n",
    "        ax.axvline(residuals.mean(), color='orange', linestyle='-.', linewidth=1.5,\n",
    "                   label=f'Mean={residuals.mean():.4f}')\n",
    "        ax.set_title(name, fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel(\"Residual (Aktual - Prediksi)\", fontsize=9)\n",
    "        ax.set_ylabel(\"Frekuensi\", fontsize=9)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\"Distribusi Error Residual\",\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"08_error_distribution\")\n",
    "\n",
    "\n",
    "def plot_tuning_heatmap(df_tuning: pd.DataFrame):\n",
    "    \"\"\"Gambar 9: Heatmap hasil hyperparameter tuning.\"\"\"\n",
    "    # Pivot per LR dan units kombinasi (avg across epochs)\n",
    "    df_tuning[\"units\"] = (df_tuning[\"units_1\"].astype(str) + \"x\"\n",
    "                          + df_tuning[\"units_2\"].astype(str))\n",
    "    pivot = df_tuning.groupby([\"lr\", \"units\"])[\"val_loss\"].min().unstack()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".6f\", cmap=\"YlOrRd_r\",\n",
    "                linewidths=0.5, ax=ax, cbar_kws={\"label\": \"Min Val Loss\"})\n",
    "    ax.set_title(\"Heatmap Hyperparameter Tuning\\n\"\n",
    "                 \"(Min Validation Loss per Kombinasi LR Ã— Hidden Units)\",\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel(\"Hidden Units (Layer1 x Layer2)\", fontsize=10)\n",
    "    ax.set_ylabel(\"Learning Rate\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    _save_fig(fig, \"09_tuning_heatmap\")\n",
    "\n",
    "\n",
    "def _save_fig(fig, name: str):\n",
    "    \"\"\"Helper menyimpan gambar.\"\"\"\n",
    "    path = PLOT_DIR / f\"{name}.png\"\n",
    "    fig.savefig(path, dpi=CFG[\"fig_dpi\"], bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"      Gambar tersimpan  : plots/{name}.png\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 8: MAIN PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    print(\"\\n\" + \"=\" * 65)\n",
    "    print(\"  MEMULAI PIPELINE PENELITIAN\")\n",
    "    print(f\"  Waktu mulai: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 1-2: Preprocessing & EDA\n",
    "    # ------------------------------------------------------------------\n",
    "    df_raw, df_scaled, scalers, stats = full_preprocessing(DATA_PATH)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 2: Korelasi Pearson & Visualisasi EDA\n",
    "    # ------------------------------------------------------------------\n",
    "    corr_matrix = pearson_correlation_analysis(df_raw)\n",
    "\n",
    "    print(\"\\n[2/8] MEMBUAT VISUALISASI EDA ...\")\n",
    "    plot_time_series_overview(df_raw, stats)\n",
    "    plot_correlation_heatmap(corr_matrix)\n",
    "    plot_distribution(df_raw)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 3: Pembentukan Dataset\n",
    "    # ------------------------------------------------------------------\n",
    "    (X_train, X_val, X_test,\n",
    "     y_train, y_val, y_test) = split_dataset(df_scaled)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 4: Hyperparameter Tuning (Hybrid LSTM-GRU)\n",
    "    # ------------------------------------------------------------------\n",
    "    best_cfg, df_tuning = hyperparameter_tuning(\n",
    "        X_train, y_train, X_val, y_val\n",
    "    )\n",
    "    plot_tuning_heatmap(df_tuning)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 5: Training Model Final (konfigurasi terbaik)\n",
    "    # ------------------------------------------------------------------\n",
    "    print(\"\\n[5/8] TRAINING MODEL FINAL ...\")\n",
    "    best_ep = best_cfg[\"epochs\"]\n",
    "    best_lr = best_cfg[\"lr\"]\n",
    "    best_u1 = best_cfg[\"units_1\"]\n",
    "    best_u2 = best_cfg[\"units_2\"]\n",
    "\n",
    "    model_lstm, hist_lstm = train_model(\n",
    "        build_lstm_model(best_u1, best_u2, lr=best_lr),\n",
    "        \"LSTM\", X_train, y_train, X_val, y_val,\n",
    "        epochs=best_ep, batch_size=CFG[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    model_gru, hist_gru = train_model(\n",
    "        build_gru_model(best_u1, best_u2, lr=best_lr),\n",
    "        \"GRU\", X_train, y_train, X_val, y_val,\n",
    "        epochs=best_ep, batch_size=CFG[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    model_hybrid, hist_hybrid = train_model(\n",
    "        build_hybrid_lstm_gru_model(best_u1, best_u2, lr=best_lr),\n",
    "        \"HybridLSTMGRU\", X_train, y_train, X_val, y_val,\n",
    "        epochs=best_ep, batch_size=CFG[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    # Simpan model final\n",
    "    model_lstm.save(MODEL_DIR / \"final_LSTM.keras\")\n",
    "    model_gru.save(MODEL_DIR  / \"final_GRU.keras\")\n",
    "    model_hybrid.save(MODEL_DIR / \"final_HybridLSTMGRU.keras\")\n",
    "    print(\"      Model final tersimpan di outputs/models/\")\n",
    "\n",
    "    # Ringkasan arsitektur\n",
    "    print(\"\\n      Ringkasan Arsitektur:\")\n",
    "    for name, model in [(\"LSTM\", model_lstm),\n",
    "                        (\"GRU\", model_gru),\n",
    "                        (\"Hybrid LSTM-GRU\", model_hybrid)]:\n",
    "        print(f\"\\n      -- {name} --\")\n",
    "        model.summary(print_fn=lambda x: print(f\"         {x}\"))\n",
    "\n",
    "    # Plot learning curves\n",
    "    histories = {\n",
    "        \"LSTM\"           : hist_lstm,\n",
    "        \"GRU\"            : hist_gru,\n",
    "        \"Hybrid LSTM-GRU\": hist_hybrid,\n",
    "    }\n",
    "    plot_training_history(histories)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 6: Evaluasi Komparatif\n",
    "    # ------------------------------------------------------------------\n",
    "    models_dict = {\n",
    "        \"LSTM\"           : model_lstm,\n",
    "        \"GRU\"            : model_gru,\n",
    "        \"Hybrid LSTM-GRU\": model_hybrid,\n",
    "    }\n",
    "    df_metrics, all_preds = evaluate_all_models(\n",
    "        models_dict, X_test, y_test, scalers\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 7: Visualisasi Hasil\n",
    "    # ------------------------------------------------------------------\n",
    "    print(\"\\n[7/8] MEMBUAT VISUALISASI HASIL ...\")\n",
    "    plot_prediction_comparison(all_preds)\n",
    "    plot_scatter_actual_vs_pred(all_preds)\n",
    "    plot_metrics_comparison(df_metrics)\n",
    "    plot_error_distribution(all_preds)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # STEP 8: Laporan Akhir\n",
    "    # ------------------------------------------------------------------\n",
    "    elapsed = (datetime.now() - start_time).total_seconds()\n",
    "    print(\"\\n\" + \"=\" * 65)\n",
    "    print(\"  RINGKASAN HASIL AKHIR\")\n",
    "    print(\"=\" * 65)\n",
    "    print(df_metrics.to_string())\n",
    "\n",
    "    best_model_name = df_metrics[\"RMSE\"].idxmin()\n",
    "    print(f\"\\n  âœ“ Model Terbaik (RMSE terendah) : {best_model_name}\")\n",
    "    print(f\"    RMSE : {df_metrics.loc[best_model_name, 'RMSE']:.6f}\")\n",
    "    print(f\"    MAE  : {df_metrics.loc[best_model_name, 'MAE']:.6f}\")\n",
    "    print(f\"    RÂ²   : {df_metrics.loc[best_model_name, 'R2']:.6f}\")\n",
    "    print(f\"\\n  Total waktu eksekusi : {elapsed/60:.1f} menit\")\n",
    "    print(f\"  Output tersimpan di  : {OUTPUT_DIR.resolve()}\")\n",
    "    print(\"\\n  File Output:\")\n",
    "    print(\"    ğŸ“Š outputs/plots/          â†’ 9 grafik visualisasi\")\n",
    "    print(\"    ğŸ¤– outputs/models/         â†’ 3 model (.keras)\")\n",
    "    print(\"    ğŸ“‹ outputs/evaluation_metrics.csv\")\n",
    "    print(\"    ğŸ“‹ outputs/tuning_results.csv\")\n",
    "    print(\"    ğŸ“ outputs/logs/           â†’ training logs CSV\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    return df_metrics, all_preds, histories\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENTRY POINT\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_metrics, all_preds, histories = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
